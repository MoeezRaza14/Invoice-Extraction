# -*- coding: utf-8 -*-
"""Streamlit File.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1s9PcPJrzlN_m3S7mWezjGSgnxLY3eRZT
"""

import pandas as pd
import os
import re
from tabulate import tabulate
import json
import streamlit as st

df = pd.read_csv("E:\ms_vs_code\Basant T2 - 1099i1.csv", header=None)
df

def is_numeric(val):
    """ Check if a value is numeric (either int or float). """
    try:
        float(val.replace(',', ''))  # Remove commas and attempt to cast to float
        return True
    except ValueError:
        return False

def is_table_row(row_data):
    """Determine if a row looks like part of a table by checking for multiple numeric values."""
    if any(re.search(r'total|ttl', str(item), re.IGNORECASE) for item in row_data if pd.notna(item)):
        return False

    numeric_count = sum(is_numeric(item) for item in row_data if pd.notna(item))
    return numeric_count >= 2

def is_header_row(row_data):
    """Check if a row contains 'Qty', 'Quantity', or 'Quantities' in any case."""
    header_pattern = re.compile(r'description|desc.|desc|qty|quantity|quantities', re.IGNORECASE)
    return any(header_pattern.search(str(item)) for item in row_data if pd.notna(item))

def extract_table_data(df):
    """Extract table data from the dataframe, including rows with multi-level headers."""
    table_data = []
    header_row = None
    header_index = None
    next_row_as_header = False

    for index, row in df.iterrows():
        row_data = row.tolist()
        row_data = [item if pd.notna(item) else None for item in row_data]
        row_length = len(row_data)

        if row_length < 2:
            continue

        if header_row is None and is_header_row(row_data):
            header_row = row_data
            header_index = index
            next_row_as_header = True
            continue

        if next_row_as_header:
            next_row_as_header = False
            if not is_table_row(row_data):
                for i in range(len(row_data)):
                    if pd.notna(row_data[i]):
                        header_row[i] = f"{header_row[i]} {row_data[i]}" if header_row[i] else row_data[i]
                continue

        if header_row:
            if is_table_row(row_data):
                table_data.append(row_data)

    if header_row:
        table_df = pd.DataFrame(table_data, columns=header_row)

        for idx, value in enumerate(header_row):
            if value is None:
                next_row_index = header_index + 1
                if next_row_index < len(df):
                    next_row = df.iloc[next_row_index]
                    if not is_table_row(next_row.tolist()):
                        header_row[idx] = next_row[idx] if idx < len(next_row) else None

        unnamed_count = 1
        updated_header_row = []
        for item in header_row:
            if pd.isna(item) or item is None:
                updated_header_row.append(f'Unnamed: {unnamed_count}')
                unnamed_count += 1
            else:
                updated_header_row.append(item)

        table_df = pd.DataFrame(table_data, columns=updated_header_row)
    else:
        table_df = pd.DataFrame()

    return table_df

def extract_non_table_data(df):
    """Extract non-table data from the dataframe, including rows that are not part of the table."""
    non_table_data = []

    for index, row in df.iterrows():
        row_data = row.tolist()
        row_data = [item if pd.notna(item) else None for item in row_data]
        row_length = len(row_data)

        if row_length < 2:
            non_table_data.append(row_data)

    non_table_df = pd.DataFrame(non_table_data) if non_table_data else pd.DataFrame()

    return non_table_df

def add_package_type_and_reference(table_df):
    """Add 'Package Type' and 'Reference Number' columns to the table."""
    table_df['Package Type'] = None
    table_df['Reference Number'] = None

    package_keywords = ['ctn', 'ctns', 'Palette', 'Palettes', 'Box', 'boxes', 'Case', 'cases', 'EuroPalette', 'EuroPalettes']

    for keyword in package_keywords:
        if any(keyword.lower() in str(header).lower() for header in table_df.columns):
            table_df['Package Type'] = keyword.upper()
            break

def process_table(df):
    """Process table data by extracting relevant rows, adjusting headers, and adding additional columns."""
    table_df = extract_table_data(df)
    add_package_type_and_reference(table_df)

    unnamed_columns = [col for col in table_df.columns if str(col).startswith('Unnamed')]

    for col in unnamed_columns:
        if table_df[col].isna().all():
            table_df.drop(columns=[col], inplace=True)

    return table_df

def process_file(file_path):
    """Process a single file and return extracted table and non-table data."""
    df = pd.read_csv(file_path, header=None, dtype=str)
    table_df = process_table(df)
    non_table_df = extract_non_table_data(df)
    return table_df, non_table_df

def format_json_output(table_df):
    """Format the table and row data into the specified JSON structure."""
    headers = [
        {"Row": 0, "Column": col_idx, "Header Name": header}
        for col_idx, header in enumerate(table_df.columns)
    ]

    rows = [
        {"Row": row_idx, "Column": col_idx, "Data": str(data)}
        for row_idx, row in table_df.iterrows()
        for col_idx, data in enumerate(row)
    ]

    return {"Headers": headers, "Rows": rows}

# **Streamlit App Functionality**
st.title("CSV Data Extractor")

uploaded_files = st.file_uploader("Choose CSV files", accept_multiple_files=True)

if uploaded_files:
    for uploaded_file in uploaded_files:
        st.write(f"Processing file: {uploaded_file.name}")
        try:
            table_df, non_table_df = process_file(uploaded_file)

            # Display extracted table data
            if not table_df.empty:
                st.subheader("Extracted Table Data")
                st.dataframe(table_df)

                # Format JSON output
                json_output = format_json_output(table_df)

                # **Convert and display the formatted JSON**
                st.subheader("Formatted JSON Output")
                st.json(json_output)  # Display formatted JSON output

            else:
                st.warning(f"No table data found in the file: {uploaded_file.name}")

            # Display non-table data
            if not non_table_df.empty:
                st.subheader("Non-Table Data")
                st.dataframe(non_table_df)

                # **Convert non_table_df to JSON and display**
                non_table_json = non_table_df.to_json(orient='records')
                st.subheader("Non-Table Data as JSON")
                st.json(non_table_json)  # **JSON output of the non-table data**

            else:
                st.warning(f"No non-table data found in the file: {uploaded_file.name}")

        except Exception as e:
            st.error(f"Error processing file {uploaded_file.name}: {e}")